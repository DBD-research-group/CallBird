{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895283dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_root = \"/workspace/projects/callbird/datastats\"\n",
    "output_root_train = f\"{output_root}/train\"\n",
    "output_root_test = f\"{output_root}/test\"\n",
    "\n",
    "output_blacklist_ebird_train = f\"{output_root_train}/blacklist_ebird.txt\"\n",
    "output_blacklist_ebird_test = f\"{output_root_test}/blacklist_ebird.txt\"\n",
    "\n",
    "output_blacklist_naive_train = f\"{output_root_train}/blacklist_naive.txt\"\n",
    "output_blacklist_naive_test = f\"{output_root_test}/blacklist_naive.txt\"\n",
    "\n",
    "output_blacklist_files_train = f\"{output_root_train}/blacklist_files.txt\"\n",
    "\n",
    "file_calltype_mapping = \"/workspace/projects/callbird/datastats/call_types_list\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a300e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from callbird.src.readUtils import readLabeledMapping, readCommentedList\n",
    "from datasets import load_dataset, Features, Value, concatenate_datasets\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4772c076",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b480bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = load_dataset(\n",
    "    \"csv\",\n",
    "    data_files = \"/workspace/oekofor/testset/labels/*.csv\",\n",
    "    features = Features({ # TODO: Add all features available in BirdSet\n",
    "        \"ebird_code\": Value(\"string\"),\n",
    "        \"common_name\": Value(\"string\"),\n",
    "        \"vocalization_type\": Value(\"string\"),\n",
    "        \"start_time\": Value(\"float\"),\n",
    "        \"end_time\": Value(\"float\"),\n",
    "        \"audio_filename\": Value(\"string\"),\n",
    "    }),\n",
    "    cache_dir = cache_dir,\n",
    "    num_proc = 1,\n",
    "    trust_remote_code = True, # While not needed for local datasets, it is kept for consistency\n",
    ")\n",
    "original_test_dataset_length = len(test_dataset[\"train\"])\n",
    "\n",
    "train_dataset = load_dataset(\n",
    "    \"csv\",\n",
    "    data_files = \"/workspace/oekofor/trainset/csvlabels/*.csv\",\n",
    "    features = Features({ # TODO: Add all features available in BirdSet\n",
    "        \"ebird_code\": Value(\"string\"),\n",
    "        \"call_type\": Value(\"string\"),\n",
    "        \"start_sample [s]\": Value(\"float\"),\n",
    "        \"end_sample [s]\": Value(\"float\"),\n",
    "        \"actual_filename\": Value(\"string\"),\n",
    "    }),\n",
    "    delimiter=\";\",\n",
    "    cache_dir = cache_dir,\n",
    "    num_proc = 1,\n",
    "    trust_remote_code = True, # While not needed for local datasets, it is kept for consistency\n",
    ")\n",
    "original_train_dataset_length = len(train_dataset[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cc3b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.map(lambda x: {\"ebird_code\": x[\"ebird_code\"] if x[\"ebird_code\"] is not None else \"NA\"})\n",
    "# For the test dataset we need to handle a special case, where there are two different reasons a ebird code is missing\n",
    "test_dataset = test_dataset.map(lambda x: {\"ebird_code\": x[\"ebird_code\"] if x[\"ebird_code\"] is not None else (\"UNKNOWN\" if x[\"common_name\"] == \"Bird\" else \"NA\")})\n",
    "\n",
    "train_dataset = train_dataset.map(lambda x: {\"call_type\": x[\"call_type\"] if x[\"call_type\"] is not None else \"NA\"})\n",
    "test_dataset = test_dataset.map(lambda x: {\"vocalization_type\": x[\"vocalization_type\"] if x[\"vocalization_type\"] is not None else \"NA\"})\n",
    "\n",
    "oritinal_test_data_copyset = test_dataset\n",
    "oritinal_train_data_copyset = train_dataset\n",
    "\n",
    "# list all call types\n",
    "print(\"Unique call types in train dataset:\", set(train_dataset['train']['call_type']))\n",
    "print(\"Unique vocalization types in test dataset:\", set(test_dataset['train']['vocalization_type']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6191a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ebirdcodes = train_dataset[\"train\"].unique(\"ebird_code\")\n",
    "test_ebirdcodes = test_dataset[\"train\"].unique(\"ebird_code\")\n",
    "\n",
    "print(f\"Train call types ('{len(train_ebirdcodes)}'):\", train_ebirdcodes)\n",
    "print(f\"Test call types ('{len(test_ebirdcodes)}'):\", test_ebirdcodes)\n",
    "\n",
    "train_blacklist = set(train_ebirdcodes) - set(test_ebirdcodes)\n",
    "test_blacklist = set(test_ebirdcodes) - set(train_ebirdcodes)\n",
    "\n",
    "print(f\"Train blacklist ('{len(train_blacklist)}'):\", train_blacklist)\n",
    "print(f\"Test blacklist ('{len(test_blacklist)}'):\", test_blacklist)\n",
    "\n",
    "with open(output_blacklist_ebird_train, \"w\") as f:\n",
    "    f.write(\"# eBird codes not present in the test set\\n\")\n",
    "    for code in train_blacklist:\n",
    "        f.write(f\"{code}\\n\")\n",
    "\n",
    "with open(output_blacklist_ebird_test, \"w\") as f:\n",
    "    f.write(\"# eBird codes not present in the train set\\n\")\n",
    "    for code in test_blacklist:\n",
    "        f.write(f\"{code}\\n\")\n",
    "\n",
    "# Apply blacklists\n",
    "ebird_blacklist_train = readCommentedList(output_blacklist_ebird_train)\n",
    "ebird_blacklist_test = readCommentedList(output_blacklist_ebird_test)\n",
    "\n",
    "test_dataset = test_dataset.filter(lambda x: x[\"ebird_code\"] not in ebird_blacklist_test)\n",
    "train_dataset = train_dataset.filter(lambda x: x[\"ebird_code\"] not in ebird_blacklist_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed34a316",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_calltypes = train_dataset[\"train\"].unique(\"call_type\")\n",
    "test_calltypes = test_dataset[\"train\"].unique(\"vocalization_type\")\n",
    "\n",
    "print(f\"Train call types ('{len(train_calltypes)}'):\", train_calltypes)\n",
    "print(f\"Test call types ('{len(test_calltypes)}'):\", test_calltypes)\n",
    "\n",
    "calltype_mapping = readLabeledMapping(file_calltype_mapping, None)\n",
    "calltype_mapping_test = calltype_mapping[\"test\"]\n",
    "calltype_mapping_train = calltype_mapping[\"train\"]\n",
    "\n",
    "print(f\"Call type mapping test ('{len(calltype_mapping_test)}'):\", calltype_mapping_test)\n",
    "print(f\"Call type mapping train ('{len(calltype_mapping_train)}'):\", calltype_mapping_train)\n",
    "\n",
    "# Ensuring valid call type mapping\n",
    "missing_train = set(train_calltypes) - set(calltype_mapping_train.keys())\n",
    "missing_test = set(test_calltypes) - set(calltype_mapping_test.keys())\n",
    "\n",
    "if missing_train:\n",
    "    print(f\"\\nMissing call types in train mapping: {missing_train}\")\n",
    "if missing_test:\n",
    "    print(f\"\\nMissing call types in test mapping: {missing_test}\")\n",
    "if not missing_train and not missing_test:\n",
    "    print(\"\\nAll call types are mapped correctly.\")\n",
    "\n",
    "# Update datasets with call type mappings\n",
    "train_dataset = train_dataset.map(lambda x: {\"short_call_type\": calltype_mapping_train.get(x[\"call_type\"], None)}) # Using None to force an error if the call type is not found\n",
    "test_dataset = test_dataset.map(lambda x: {\"short_call_type\": calltype_mapping_test.get(x[\"vocalization_type\"], None)}) # Using None to force an error if the vocalization type is not found\n",
    "\n",
    "# filter out sample with \"null\" as short call type\n",
    "# train_dataset = train_dataset.filter(lambda x: x[\"short_call_type\"] != \"null\")\n",
    "# test_dataset = test_dataset.filter(lambda x: x[\"short_call_type\"] != \"null\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811d967b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = test_dataset.map(lambda x: { \"ebird_code_and_call\": f\"{x['ebird_code']}_{x['short_call_type']}\" })\n",
    "train_dataset = train_dataset.map(lambda x: { \"ebird_code_and_call\": f\"{x['ebird_code']}_{x['short_call_type']}\" })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62eeb375",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ebird_call_codes = train_dataset[\"train\"].unique(\"ebird_code_and_call\")\n",
    "test_ebird_call_codes = test_dataset[\"train\"].unique(\"ebird_code_and_call\")\n",
    "\n",
    "print(f\"Train naive classes ('{len(train_ebird_call_codes)}'):\", train_ebird_call_codes)\n",
    "print(f\"Test naive classes ('{len(test_ebird_call_codes)}'):\", test_ebird_call_codes)\n",
    "\n",
    "train_blacklist = set(train_ebird_call_codes) - set(test_ebird_call_codes)\n",
    "test_blacklist = set(test_ebird_call_codes) - set(train_ebird_call_codes)\n",
    "\n",
    "print(f\"Train blacklist ('{len(train_blacklist)}'):\", train_blacklist)\n",
    "print(f\"Test blacklist ('{len(test_blacklist)}'):\", test_blacklist)\n",
    "\n",
    "with open(output_blacklist_naive_train, \"w\") as f:\n",
    "    f.write(\"# eBird codes not present in the test set\\n\")\n",
    "    for code in train_blacklist:\n",
    "        f.write(f\"{code}\\n\")\n",
    "\n",
    "with open(output_blacklist_naive_test, \"w\") as f:\n",
    "    f.write(\"# eBird codes not present in the train set\\n\")\n",
    "    for code in test_blacklist:\n",
    "        f.write(f\"{code}\\n\")\n",
    "\n",
    "# Apply blacklists\n",
    "test_blacklist = readCommentedList(output_blacklist_naive_test)\n",
    "train_blacklist = readCommentedList(output_blacklist_naive_train)\n",
    "\n",
    "test_dataset = test_dataset.filter(lambda x: x[\"ebird_code_and_call\"] not in test_blacklist)\n",
    "train_dataset = train_dataset.filter(lambda x: x[\"ebird_code_and_call\"] not in train_blacklist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900aec14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_samples(dataset, column_name, target_value, max_samples):\n",
    "    \"\"\"\n",
    "    Performaned downsampling method to reduce the number of samples for a specific column value in a dataset.\n",
    "\n",
    "    Args:\n",
    "        dataset (DatasetDict): The dataset to be downsampled.\n",
    "        column_name (str): The name of the column to be downsampled.\n",
    "        target_value (str): The specific value in the column to be downsampled.\n",
    "        max_samples (int): The maximum number of samples to retain for the target value.\n",
    "    Returns:\n",
    "        DatasetDict: The downsampled dataset.\n",
    "    \"\"\"\n",
    "    # Create own dataset only containing target column samples\n",
    "    target_column_dataset = dataset.filter(lambda x: x[column_name] == target_value)\n",
    "    # Create dataset containing all other samples\n",
    "    other_dataset = dataset.filter(lambda x: x[column_name] != target_value)\n",
    "    # Downsample the target column dataset to the specified number of samples\n",
    "    target_column_dataset = target_column_dataset['train'].shuffle(seed=42).select(range(min(max_samples, len(target_column_dataset['train']))))\n",
    "    # Merge the downsampled target column dataset with the rest of the dataset\n",
    "    dataset['train'] = concatenate_datasets([other_dataset['train'], target_column_dataset])\n",
    "    return dataset\n",
    "\n",
    "# For performance reasons we manually set the downsampling values\n",
    "# The specfic order of downsampling matters and produces filters the least amount of samples\n",
    "### train_dataset = reduce_samples(train_dataset, \"call_type\", \"s (Gesang)\", 15_000)\n",
    "### train_dataset = reduce_samples(train_dataset, \"ebird_code\", \"NA\", 4000)\n",
    "### train_dataset = reduce_samples(train_dataset, \"ebird_code\", \"grswoo\", 4000)\n",
    "# train_dataset = reduce_samples(train_dataset, \"ebird_code\", \"eurbla\", 4000)\n",
    "# train_dataset = reduce_samples(train_dataset, \"ebird_code\", \"sonthr1\", 4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709a0e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Remove low count call types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c178de2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print four most common ebird_code and call_type values from both datasets\n",
    "from collections import Counter\n",
    "train_ebird_code_counts = Counter(train_dataset['train']['ebird_code'])\n",
    "test_ebird_code_counts = Counter(test_dataset['train']['ebird_code'])\n",
    "train_call_type_counts = Counter(train_dataset['train']['call_type'])\n",
    "test_vocalization_type_counts = Counter(test_dataset['train']['vocalization_type'])\n",
    "\n",
    "print(\"Most common eBird codes in train dataset:\", train_ebird_code_counts.most_common(4))\n",
    "print(\"Most common eBird codes in test dataset:\", test_ebird_code_counts.most_common(4))\n",
    "print(\"Most common call types in train dataset:\", train_call_type_counts.most_common(4))\n",
    "print(\"Most common vocalization types in test dataset:\", test_vocalization_type_counts.most_common(4))\n",
    "\n",
    "filtered_test_dataset_length = len(test_dataset[\"train\"])\n",
    "filtered_train_dataset_length = len(train_dataset[\"train\"])\n",
    "print(f\"Original test dataset length: {original_test_dataset_length}, filtered length: {filtered_test_dataset_length}\")\n",
    "print(f\"Original train dataset length: {original_train_dataset_length}, filtered length: {filtered_train_dataset_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049995ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a table with ebird_code and call type in the rows and columns respectively with the number of samples in each cell determining how much they got filtered\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "def create_filter_diff_table(original_dataset, filtered_dataset, dataset_name):\n",
    "    original_df = pd.DataFrame(original_dataset['train'])\n",
    "    filtered_df = pd.DataFrame(filtered_dataset['train'])\n",
    "    \n",
    "    # Create a pivot table for the original dataset\n",
    "    original_pivot = pd.pivot_table(original_df, index='ebird_code', columns='call_type' if 'call_type' in original_df.columns else 'vocalization_type', aggfunc='size', fill_value=0)\n",
    "    \n",
    "    # Create a pivot table for the filtered dataset\n",
    "    filtered_pivot = pd.pivot_table(filtered_df, index='ebird_code', columns='call_type' if 'call_type' in filtered_df.columns else 'vocalization_type', aggfunc='size', fill_value=0)\n",
    "    \n",
    "    # Align the two pivot tables to ensure they have the same shape\n",
    "    all_ebird_codes = original_pivot.index.union(filtered_pivot.index)\n",
    "    all_call_types = original_pivot.columns.union(filtered_pivot.columns)\n",
    "    \n",
    "    original_pivot = original_pivot.reindex(index=all_ebird_codes, columns=all_call_types, fill_value=0)\n",
    "    filtered_pivot = filtered_pivot.reindex(index=all_ebird_codes, columns=all_call_types, fill_value=0)\n",
    "    \n",
    "    # Calculate the difference\n",
    "    difference = original_pivot - filtered_pivot\n",
    "\n",
    "    # Save to CSV\n",
    "    difference.to_csv(f\"{output_root}/{dataset_name}_filter_difference.csv\")\n",
    "    \n",
    "    return difference\n",
    "\n",
    "create_filter_diff_table(oritinal_test_data_copyset, test_dataset, \"test_data_diff\")\n",
    "create_filter_diff_table(oritinal_train_data_copyset, train_dataset, \"train_data_diff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736fc2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list count of call types in both datasets\n",
    "train_call_type_counts = Counter(train_dataset['train']['call_type'])\n",
    "test_vocalization_type_counts = Counter(test_dataset['train']['vocalization_type'])\n",
    "print(\"Call type counts in train dataset:\", dict(train_call_type_counts))\n",
    "print(\"Vocalization type counts in test dataset:\", dict(test_vocalization_type_counts))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "birdset-xS3fZVNL-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
